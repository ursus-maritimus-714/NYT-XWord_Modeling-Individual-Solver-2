{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1dcb9885",
   "metadata": {},
   "source": [
    "### Introduction to Preprocessing: DecayTime-Weighting Experiments-Comparing SOS-Adjusted to Non-SOS Adjusted Versions of Optimized Recent Past Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8fc727e",
   "metadata": {},
   "source": [
    "This preprocessing step looks specifically at comparison of linear prediction quality for non-'Strength of Schedule' adjusted and 'Strength of Schedule' adjusted forms ('IS_pds_l10_ndw' and 'IS_pds_l10_dw_SOS_adj', respectively) for IS2 past performance identified in the previous preprocessing step (03a_IS2_Preprocessing_DTW_Experiments) \n",
    "\n",
    "CONCLUSION: The SOS-Adjusted version yields a SUBSTANTIALLY better prediction than the non-SOS version:\n",
    "\n",
    "l10 non-SOS adjusted version\n",
    "Training: (9.467881123742533, 1.1936856196221093), Testing: 10.253582416968488\n",
    "\n",
    "l10 SOS adjusted version\n",
    "Training: (9.323487546635262, 1.2065005232644828), Testing: 10.135272303754874"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e179e73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import __version__ as sklearn_version\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.model_selection import train_test_split, cross_validate, GridSearchCV, learning_curve\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "import datetime\n",
    "#from library.sb_utils import save_file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e352c49",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9cc5018d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P_Date</th>\n",
       "      <th>P_Date_str</th>\n",
       "      <th>IS2_Completed</th>\n",
       "      <th>Comp_Date</th>\n",
       "      <th>Comp_Date_str</th>\n",
       "      <th>DOW</th>\n",
       "      <th>DOW_num</th>\n",
       "      <th>Grid Size</th>\n",
       "      <th>IS2_ST(m)</th>\n",
       "      <th>IS_pds_l10_ndw</th>\n",
       "      <th>...</th>\n",
       "      <th>Circle_Count</th>\n",
       "      <th>Shade_Count</th>\n",
       "      <th>Unusual_Sym</th>\n",
       "      <th>Black_Square_Fill</th>\n",
       "      <th>Outside_Grid</th>\n",
       "      <th>Unchecked_Sq</th>\n",
       "      <th>Uniclue</th>\n",
       "      <th>Duplicate_Answers</th>\n",
       "      <th>Quantum</th>\n",
       "      <th>Wordplay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-05-11 00:00:00</td>\n",
       "      <td>2022-05-11</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2024-02-29 19:58:44</td>\n",
       "      <td>2024-02-29</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>8.166667</td>\n",
       "      <td>10.995000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-05-18 00:00:00</td>\n",
       "      <td>2022-05-18</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2024-02-29 17:34:25</td>\n",
       "      <td>2024-02-29</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.783333</td>\n",
       "      <td>11.678333</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-02-28 00:00:00</td>\n",
       "      <td>2024-02-28</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2024-02-28 18:02:10</td>\n",
       "      <td>2024-02-28</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>7.033333</td>\n",
       "      <td>11.625000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-05-25 00:00:00</td>\n",
       "      <td>2022-05-25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2024-02-27 20:57:43</td>\n",
       "      <td>2024-02-27</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>11.750000</td>\n",
       "      <td>11.531667</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-06-01 00:00:00</td>\n",
       "      <td>2022-06-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2024-02-24 21:13:46</td>\n",
       "      <td>2024-02-24</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>16.200000</td>\n",
       "      <td>11.161667</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                P_Date  P_Date_str  IS2_Completed            Comp_Date  \\\n",
       "0  2022-05-11 00:00:00  2022-05-11            1.0  2024-02-29 19:58:44   \n",
       "1  2022-05-18 00:00:00  2022-05-18            1.0  2024-02-29 17:34:25   \n",
       "2  2024-02-28 00:00:00  2024-02-28            1.0  2024-02-28 18:02:10   \n",
       "3  2022-05-25 00:00:00  2022-05-25            1.0  2024-02-27 20:57:43   \n",
       "4  2022-06-01 00:00:00  2022-06-01            1.0  2024-02-24 21:13:46   \n",
       "\n",
       "  Comp_Date_str        DOW  DOW_num  Grid Size  IS2_ST(m)  IS_pds_l10_ndw  \\\n",
       "0    2024-02-29  Wednesday      4.0          1   8.166667       10.995000   \n",
       "1    2024-02-29  Wednesday      4.0          1   6.783333       11.678333   \n",
       "2    2024-02-28  Wednesday      4.0          1   7.033333       11.625000   \n",
       "3    2024-02-27  Wednesday      4.0          1  11.750000       11.531667   \n",
       "4    2024-02-24  Wednesday      4.0          1  16.200000       11.161667   \n",
       "\n",
       "   ...  Circle_Count  Shade_Count  Unusual_Sym Black_Square_Fill  \\\n",
       "0  ...             0            0            0                 0   \n",
       "1  ...             0            0            0                 0   \n",
       "2  ...             0            0            0                 0   \n",
       "3  ...             0            0            0                 0   \n",
       "4  ...            16            0            0                 0   \n",
       "\n",
       "   Outside_Grid  Unchecked_Sq  Uniclue  Duplicate_Answers  Quantum  Wordplay  \n",
       "0             0             0        0                  0        0       3.0  \n",
       "1             0             0        0                  0        0       3.0  \n",
       "2             0             0        0                  0        0       3.0  \n",
       "3             0             0        0                  0        0       4.0  \n",
       "4             0             0        0                  0        0       1.0  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../../data/df3.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95327794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1230 entries, 0 to 1229\n",
      "Data columns (total 43 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   P_Date                  1230 non-null   object \n",
      " 1   P_Date_str              1230 non-null   object \n",
      " 2   IS2_Completed           1228 non-null   float64\n",
      " 3   Comp_Date               1230 non-null   object \n",
      " 4   Comp_Date_str           1230 non-null   object \n",
      " 5   DOW                     1230 non-null   object \n",
      " 6   DOW_num                 1230 non-null   float64\n",
      " 7   Grid Size               1230 non-null   int64  \n",
      " 8   IS2_ST(m)               1230 non-null   float64\n",
      " 9   IS_pds_l10_ndw          1223 non-null   float64\n",
      " 10  IS_pds_l10_stdev        1216 non-null   float64\n",
      " 11  IS_pds_l10_ndw_SOS_adj  1223 non-null   float64\n",
      " 12  GMST(m)                 1230 non-null   float64\n",
      " 13  Constructors            1230 non-null   object \n",
      " 14  Words                   1230 non-null   int64  \n",
      " 15  Blocks                  1230 non-null   int64  \n",
      " 16  Unused_Letters          1230 non-null   int64  \n",
      " 17  Stacks                  1230 non-null   int64  \n",
      " 18  Unique_Answers          1230 non-null   int64  \n",
      " 19  Rebus_Count             1230 non-null   int64  \n",
      " 20  Rebus_Unique            1230 non-null   int64  \n",
      " 21  Cheater_Squares         1230 non-null   int64  \n",
      " 22  AWL                     1230 non-null   float64\n",
      " 23  Scrabble_Score          1151 non-null   float64\n",
      " 24  Scrabble_Avg            1230 non-null   float64\n",
      " 25  FITB                    1230 non-null   int64  \n",
      " 26  Cross_Ref_Clues         1230 non-null   int64  \n",
      " 27  Scrabble_Illegal        1230 non-null   int64  \n",
      " 28  Open_Squares            1230 non-null   int64  \n",
      " 29  Freshness_Factor        1230 non-null   float64\n",
      " 30  Overall_Freshness%      1230 non-null   float64\n",
      " 31  Day_Freshness%          1230 non-null   float64\n",
      " 32  Duplicate_Clues         1230 non-null   int64  \n",
      " 33  Circle_Count            1230 non-null   int64  \n",
      " 34  Shade_Count             1230 non-null   int64  \n",
      " 35  Unusual_Sym             1230 non-null   int64  \n",
      " 36  Black_Square_Fill       1230 non-null   int64  \n",
      " 37  Outside_Grid            1230 non-null   int64  \n",
      " 38  Unchecked_Sq            1230 non-null   int64  \n",
      " 39  Uniclue                 1230 non-null   int64  \n",
      " 40  Duplicate_Answers       1230 non-null   int64  \n",
      " 41  Quantum                 1230 non-null   int64  \n",
      " 42  Wordplay                1096 non-null   float64\n",
      "dtypes: float64(14), int64(23), object(6)\n",
      "memory usage: 413.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d17799",
   "metadata": {},
   "source": [
    "### Create Feature Variants for Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa480d1",
   "metadata": {},
   "source": [
    "### Filter Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70a42338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# strip down df to just the columns we need to evaluate SOS and non-SOS adj versions of IS2 RPB\n",
    "df1 = df[['DOW', 'Comp_Date', 'Comp_Date_str', 'IS2_ST(m)', 'IS_pds_l10_ndw', 'IS_pds_l10_ndw_SOS_adj']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51495d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter out Sunday\n",
    "df1 =df1[df1[\"DOW\"]!=\"Sunday\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94a9a066",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove the first solve period (2018-2019) to calculate sample averages by day\n",
    "df1 = df1[df1['Comp_Date_str'].str.contains(\"2020|2021|2022|2023|2024\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6164441",
   "metadata": {},
   "source": [
    "Creating df variants with only the columns we will need to generate the benchmark models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4674aae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filter=df1.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a027a7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_model1 = df_filter[[\"IS2_ST(m)\", \"IS_pds_l10_ndw\"]]\n",
    "df_model1 = df_filter[[\"IS2_ST(m)\", \"IS_pds_l10_ndw_SOS_adj\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "55f787a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 979 entries, 0 to 1219\n",
      "Data columns (total 2 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   IS2_ST(m)               979 non-null    float64\n",
      " 1   IS_pds_l10_ndw_SOS_adj  979 non-null    float64\n",
      "dtypes: float64(2)\n",
      "memory usage: 22.9 KB\n"
     ]
    }
   ],
   "source": [
    "df_model1.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f76d820",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "37dfcba4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(783.2, 195.8)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_model1) * .80, len(df_model1) * .20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "41207c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_model1.drop(columns='IS2_ST(m)'), \n",
    "                                                    df_model1[\"IS2_ST(m)\"], test_size=0.20, \n",
    "                                                    random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9aadc9a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((783,), (196,))"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7b3da5c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1016     6.483333\n",
       "379     18.783333\n",
       "499     34.400000\n",
       "152     35.233333\n",
       "1056    16.100000\n",
       "          ...    \n",
       "750     23.733333\n",
       "800     25.066667\n",
       "709     19.550000\n",
       "743     23.016667\n",
       "186      7.283333\n",
       "Name: IS2_ST(m), Length: 783, dtype: float64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3944cffa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((783, 1), (196, 1))"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "bbc338ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.32660706683695"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a297aad7",
   "metadata": {},
   "source": [
    "### Benchmark Linear Model Based on Last N Day-Specific Puzzles With X Decay Weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2dffb29e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 783 entries, 1016 to 186\n",
      "Data columns (total 1 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   IS_pds_l10_ndw_SOS_adj  783 non-null    float64\n",
      "dtypes: float64(1)\n",
      "memory usage: 12.2 KB\n"
     ]
    }
   ],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3f05e589",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_pipe = make_pipeline(\n",
    "    SimpleImputer(strategy='median'), \n",
    "    StandardScaler(),\n",
    "    SelectKBest(f_regression),\n",
    "    LinearRegression()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3b6274eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['memory', 'steps', 'verbose', 'simpleimputer', 'standardscaler', 'selectkbest', 'linearregression', 'simpleimputer__add_indicator', 'simpleimputer__copy', 'simpleimputer__fill_value', 'simpleimputer__missing_values', 'simpleimputer__strategy', 'simpleimputer__verbose', 'standardscaler__copy', 'standardscaler__with_mean', 'standardscaler__with_std', 'selectkbest__k', 'selectkbest__score_func', 'linearregression__copy_X', 'linearregression__fit_intercept', 'linearregression__n_jobs', 'linearregression__normalize', 'linearregression__positive'])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dict of available parameters for linear regression pipe\n",
    "lr_pipe.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8d45a3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define search grid parameters\n",
    "k = [k+1 for k in range(len(X_train.columns))]\n",
    "\n",
    "grid_params = {\n",
    "    'standardscaler': [StandardScaler(), None],\n",
    "    'simpleimputer__strategy': ['mean', 'median'],\n",
    "    'selectkbest__k': k\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "03fa5d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Call `GridSearchCV` with linear regression pipeline, passing in the above `grid_params`\n",
    "#dict for parameters to evaluate with 5-fold cross-validation\n",
    "lr_grid_cv = GridSearchCV(lr_pipe, param_grid=grid_params, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c1947d57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('simpleimputer',\n",
       "                                        SimpleImputer(strategy='median')),\n",
       "                                       ('standardscaler', StandardScaler()),\n",
       "                                       ('selectkbest',\n",
       "                                        SelectKBest(score_func=<function f_regression at 0x0000016172DE3310>)),\n",
       "                                       ('linearregression',\n",
       "                                        LinearRegression())]),\n",
       "             param_grid={'selectkbest__k': [1],\n",
       "                         'simpleimputer__strategy': ['mean', 'median'],\n",
       "                         'standardscaler': [StandardScaler(), None]})"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Conduct grid search for this model\n",
    "lr_grid_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a1106123",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'selectkbest__k': 1,\n",
       " 'simpleimputer__strategy': 'mean',\n",
       " 'standardscaler': StandardScaler()}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Best params from grid search for this model\n",
    "lr_grid_cv.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95754b7d",
   "metadata": {},
   "source": [
    "### Linear Model Metrics From RPB Variant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b934d9b",
   "metadata": {},
   "source": [
    "#### R-squared (COD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9fe2be9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.63279746, 0.56704739, 0.52951961, 0.59047458, 0.3963074 ])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cross-validation defaults to R^2 metric for scoring regression\n",
    "lr_best_cv_results = cross_validate(lr_grid_cv.best_estimator_, X_train, y_train, cv=5)\n",
    "lr_best_scores = lr_best_cv_results['test_score']\n",
    "lr_best_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ff3d458a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.543229288606841, 0.08074140564426967)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training set CV mean and std\n",
    "np.mean(lr_best_scores), np.std(lr_best_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb63283c",
   "metadata": {},
   "source": [
    "#### Mean Absolute Error (MAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "73d54fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_neg_mae = cross_validate(lr_grid_cv.best_estimator_, X_train, y_train, \n",
    "                            scoring='neg_mean_absolute_error', cv=5, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6ed58255",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5.7172098290131785, 0.44907010240202266)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training set MAE and STD \n",
    "lr_mae_mean = np.mean(-1 * lr_neg_mae['test_score'])\n",
    "lr_mae_std = np.std(-1 * lr_neg_mae['test_score'])\n",
    "MAE_LR_train = lr_mae_mean, lr_mae_std\n",
    "MAE_LR_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3142ce5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.165079615172858"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test set mean\n",
    "MAE_LR_test = mean_absolute_error(y_test, lr_grid_cv.best_estimator_.predict(X_test))\n",
    "MAE_LR_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd96b16",
   "metadata": {},
   "source": [
    "#### Mean Squared Error (MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d7bb4408",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_neg_mse = cross_validate(lr_grid_cv.best_estimator_, X_train, y_train, \n",
    "                            scoring='neg_mean_squared_error', cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "590c02f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(88.38306354490024, 22.468985879832516)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training set CV mean and std\n",
    "lr_mse_mean = np.mean(-1 * lr_neg_mse['test_score'])\n",
    "lr_mse_std = np.std(-1 * lr_neg_mse['test_score'])\n",
    "MSE_LR_train = lr_mse_mean, lr_mse_std\n",
    "MSE_LR_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ec4b5820",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102.72374467126065"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test set mean\n",
    "MSE_LR_test = mean_squared_error(y_test, lr_grid_cv.best_estimator_.predict(X_test))\n",
    "MSE_LR_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e903f84c",
   "metadata": {},
   "source": [
    "#### Root Mean Square Error (RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3400ccba",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_neg_rmse = cross_validate(lr_grid_cv.best_estimator_, X_train, y_train, \n",
    "                            scoring='neg_root_mean_squared_error', cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "feef3271",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9.323487546635262, 1.2065005232644828)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training set CV mean and std\n",
    "lr_rmse_mean = np.mean(-1 * lr_neg_rmse['test_score'])\n",
    "lr_rmse_std = np.std(-1 * lr_neg_rmse['test_score'])\n",
    "RMSE_LR_train = lr_rmse_mean, lr_rmse_std\n",
    "RMSE_LR_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ecd941f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.135272303754874"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test set mean\n",
    "RMSE_LR_test = np.sqrt(mean_squared_error(y_test, lr_grid_cv.best_estimator_.predict(X_test)))\n",
    "RMSE_LR_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04d3732",
   "metadata": {},
   "source": [
    "New Run: 03/02/2024\n",
    "Note: Random state now 12 across model variants for IS2. ood mean balance betwee training and testing at that state.\n",
    "\n",
    "l10 non-SOS adjusted version\n",
    "Training: (9.467881123742533, 1.1936856196221093), Testing: 10.253582416968488\n",
    "\n",
    "l10 SOS adjusted version\n",
    "Training: (9.323487546635262, 1.2065005232644828), Testing: 10.135272303754874"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "598d76ec",
   "metadata": {},
   "source": [
    "Results for NO DECAY WEIGHT Variants (RMSE) deviation in minutes (gradual decay weighting for GMS, which impacts SOS calc). \n",
    "This series 2018-2019 solves HAVE been removed upfront\n",
    "\n",
    "l10 non-SOS adjusted version\n",
    "Training: (9.198646446096195, 0.6999090426716712), Testing: 10.815823998794091\n",
    "\n",
    "l10 SOS adjusted version\n",
    "Training: (9.15468258486095, 0.6532299354795762) , Testing: 10.398201272345949"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ca4cab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
